{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emission AI\n",
    "\n",
    "#### Microsoft AI for Earth Project\n",
    "AI Monitoring Coal-fired Power Plant Emission from Space \n",
    "#### Team Members\n",
    "Ziheng Sun, Ahmed Alnaim, Zack Chester, Daniel Tong\n",
    "#### Date\n",
    "4/30/2020-10/30/2021\n",
    "#### Abstract\n",
    "The goal is to build a reusable machine learning model to estimate the emission of coal-fired power plants by satellite observations. The machine learning model will be trained on the monitoring data of the power plants collected from EPA eGRID, and the remote sensed datasets of TROPOMI on Sentinel 5 Precursor and the meterological observations from MERRA.\n",
    "\n",
    "The model will take remote sensing records as inputs, and output an estimated NOX emission daily volume. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read CSV\n",
    "\n",
    "The demo CSV files are located in the folder `data`. The CSV initially contains six columns: Facility ID (EPA Code of PP), Latitude, Longitude, Date, EPA Daily NO2 divided by 1e+05, TROPOMI NO2_column_number_density (Total vertical column of NO2, ratio of the slant column density of NO2 and the total air mass factor). Both [EPA](https://www.epa.gov/egrid), [TROPOMI](http://www.tropomi.eu/) and [MERRA](https://gmao.gsfc.nasa.gov/reanalysis/MERRA/) datasets can be accessed and retrieval free of charge. \n",
    "\n",
    "One preprocessing step is to turn the date column into three separate columns as the machine learning cannot parse date strings as input. It need be turned into numeric values. We transform the date column into dayofweek, dayofmonth, and dayofyear. The original date column is excluded from the training dataset to pass the data type checker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tropomi_epa_kvps_NO2_2018_56.csv', 'tropomi_epa_kvps_NO2_2019_56.csv']\n",
      "==================>\n",
      "         FID      Latitude     Longitude  EPA_NO2/100000  TROPOMI*1000  \\\n",
      "count  167.0  1.670000e+02  1.670000e+02      167.000000    167.000000   \n",
      "mean    56.0  3.148802e+01 -8.791075e+01        0.202637      0.073023   \n",
      "std      0.0  1.425359e-14  8.552157e-14        0.095789      0.017048   \n",
      "min     56.0  3.148802e+01 -8.791075e+01        0.000180      0.038700   \n",
      "25%     56.0  3.148802e+01 -8.791075e+01        0.142335      0.061850   \n",
      "50%     56.0  3.148802e+01 -8.791075e+01        0.202720      0.069900   \n",
      "75%     56.0  3.148802e+01 -8.791075e+01        0.242405      0.081050   \n",
      "max     56.0  3.148802e+01 -8.791075e+01        0.459370      0.127100   \n",
      "\n",
      "       Wind (Monthly)  Temp (Monthly)  Precip (Monthly)  \\\n",
      "count      167.000000      167.000000        167.000000   \n",
      "mean         3.871367      292.725567          0.000052   \n",
      "std          0.367921        7.072844          0.000026   \n",
      "min          3.383229      281.632294          0.000004   \n",
      "25%          3.605924      284.216461          0.000047   \n",
      "50%          3.678730      294.809784          0.000047   \n",
      "75%          4.234426      299.535797          0.000074   \n",
      "max          4.602291      301.860596          0.000098   \n",
      "\n",
      "       Cloud Fraction (Monthly)  \n",
      "count                167.000000  \n",
      "mean                   0.509011  \n",
      "std                    0.048822  \n",
      "min                    0.359887  \n",
      "25%                    0.486571  \n",
      "50%                    0.525576  \n",
      "75%                    0.526714  \n",
      "max                    0.691063  \n",
      "==================>\n",
      "Index(['FID', 'Latitude', 'Longitude', 'EPA_NO2/100000', 'TROPOMI*1000',\n",
      "       'Wind (Monthly)', 'Temp (Monthly)', 'Precip (Monthly)',\n",
      "       'Cloud Fraction (Monthly)', 'dayofyear', 'dayofweek', 'dayofmonth'],\n",
      "      dtype='object')\n",
      "===================>\n",
      "X_train's shape:  (111, 11)\n",
      "y_train's shape:  (111,)\n",
      "x_test's shape:  (56, 11)\n",
      "y_test's shape:  (56,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # Plotting and Visualizing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "print(os.listdir(\"data\"))\n",
    "\n",
    "# Describe the data, and get a overview\n",
    "data = pd.read_csv('data/tropomi_epa_kvps_NO2_2019_56.csv',parse_dates=[\"Date\"])\n",
    "\n",
    "print(\"==================>\")\n",
    "print(data.describe())\n",
    "\n",
    "data['dayofyear'] = data['Date'].dt.dayofyear\n",
    "data['dayofweek'] = data['Date'].dt.dayofweek\n",
    "data['dayofmonth'] = data['Date'].dt.day\n",
    "data = data.drop(columns=[\"Date\"])\n",
    "\n",
    "print(\"==================>\")\n",
    "print(data.columns)\n",
    "\n",
    "# Separating dependednt & Indepented Variables \n",
    "x = data.iloc[:, data.columns != 'EPA_NO2/100000'].values\n",
    "y = data.iloc[:, data.columns == 'EPA_NO2/100000']\n",
    "\n",
    "# show the shape of x and y to make sure they have the same length\n",
    "\n",
    "# Train Test Split at ratio 0.33\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)\n",
    "\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "print(\"===================>\")\n",
    "print(\"X_train's shape: \", x_train.shape)\n",
    "print(\"y_train's shape: \", y_train.shape)\n",
    "print(\"x_test's shape: \", x_test.shape)\n",
    "print(\"y_test's shape: \", y_test.shape)\n",
    "\n",
    "# print(y_test)\n",
    "# print(y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train Deep Learning model\n",
    "\n",
    "The hyperparameter tuning is a very troublesome task. Use Keras tensorflow model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of weights after calling the model: 12\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_182 (Dense)            (None, 500)               6000      \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 1,008,501\n",
      "Trainable params: 1,008,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6397 - mean_squared_error: 0.6397 - val_loss: 0.5876 - val_mean_squared_error: 0.5876\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6346 - mean_squared_error: 0.6346 - val_loss: 0.5796 - val_mean_squared_error: 0.5796\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.6120 - mean_squared_error: 0.6120 - val_loss: 0.5310 - val_mean_squared_error: 0.5310\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4537 - mean_squared_error: 0.4537 - val_loss: 0.2498 - val_mean_squared_error: 0.2498\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1722 - mean_squared_error: 0.1722 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0300 - mean_squared_error: 0.0300 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0408 - val_mean_squared_error: 0.0408\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.0384 - val_mean_squared_error: 0.0384\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0315 - val_mean_squared_error: 0.0315\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.0284 - val_mean_squared_error: 0.0284\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0237 - val_mean_squared_error: 0.0237\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0103 - val_mean_squared_error: 0.0103\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0a68866850>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Import and Build\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import SGD, Adagrad, Adadelta, RMSprop, Adam\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(11)),\n",
    "        layers.Dense(500, activation=\"relu\"),\n",
    "        layers.Dense(500, activation=\"relu\"),\n",
    "        layers.Dense(500, activation=\"relu\"),\n",
    "        layers.Dense(500, activation=\"relu\"),\n",
    "        layers.Dense(500, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "        \n",
    "    ]\n",
    ")  # No weights at this stage!\n",
    "\n",
    "# Call the model on a test input\n",
    "# x = tf.ones((1, 4))\n",
    "# y = model(x)\n",
    "print(\"Number of weights after calling the model:\", len(model.weights))  # 6\n",
    "\n",
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-2,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.9)\n",
    "\n",
    "# sgd = SGD(lr=lr_schedule)\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adadelta\", loss=\"mse\",  metrics=[tf.keras.metrics.mean_squared_error])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, validation_split = 0.15, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Test ML model\n",
    "\n",
    "Predict on the test dataset using the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained models to make predictions\n",
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Visualize the Results\n",
    "\n",
    "Visualization of the ML results could facilitate the intercomparison of machine learning models and identify the pros and cons of various models in different groups of data samples.  \n",
    "\n",
    "Blue dots are the true observation of EPA. Black dots are the predicted values of machine learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualizeResults(modelname, x_test, y_test, pred):\n",
    "    # Visualization\n",
    "    ## Check the fitting on training set\n",
    "    plt.scatter(x_test[:,3], y_test, color='blue')\n",
    "    plt.scatter(x_test[:,3], pred, color='black')\n",
    "#     plt.scatter(y_test, pred, color='black')\n",
    "    plt.title(modelname + ' Fit on testing set')\n",
    "    plt.xlabel('TROMPOMI-Test')\n",
    "    plt.ylabel('EPA-Test')\n",
    "    plt.show()\n",
    "    \n",
    "visualizeResults(\"Neural Network\", x_test, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Calculate quantitative metrics\n",
    "\n",
    "For a regression task, the accuracy metrics are normally mean squared error (MSE), mean absolute error (MAE), and coefficient of determination (R2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  Neural Network:   Performance:\n",
      "   MAE:  0.06508019363777977\n",
      "   MSE:  0.007504313311533799\n",
      "   R2:  0.07627266145164857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "def showAccuracyMetrics(mlmethod, model, y_test, y_pred):\n",
    "    print(\"Model \", mlmethod, \" Performance:\")\n",
    "#     print(y_test.shape, y_pred.shape)\n",
    "    \n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "    print(\"   MAE: \", mae)\n",
    "    print(\"   MSE: \", mse)\n",
    "    print(\"   R2: \", r2)\n",
    "    \n",
    "# print(y_test, linear_pred)\n",
    "\n",
    "showAccuracyMetrics(\"Neural Network: \", model, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Feature Importance\n",
    "\n",
    "0 - 'FID', \n",
    "\n",
    "1 - 'Latitude', \n",
    "\n",
    "2 - 'Longitude', \n",
    "\n",
    "3 - 'TROPOMI*1000',\n",
    "\n",
    "4 - 'Wind (Monthly)', \n",
    "\n",
    "5 - 'Temp (Monthly)', \n",
    "\n",
    "6 - 'Precip (Monthly)',\n",
    "\n",
    "7 - 'Cloud Fraction (Monthly)', \n",
    "\n",
    "8 - 'dayofyear', \n",
    "\n",
    "9 - 'dayofweek', \n",
    "\n",
    "10 - 'dayofmonth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def showImportance(model):\n",
    "    labels = ['FID', 'Latitude', 'Longitude', 'TROPOMI*1000',\\\n",
    "       'Wind (Monthly)', 'Temp (Monthly)', 'Precip (Monthly)',\\\n",
    "       'Cloud Fraction (Monthly)', 'dayofyear', 'dayofweek', 'dayofmonth']\n",
    "    # get importance\n",
    "    importance = model.best_estimator_.feature_importances_\n",
    "    print(len(labels))\n",
    "    print(importance)\n",
    "    # summarize feature importance\n",
    "    for i,v in enumerate(importance):\n",
    "        print('Feature: %s, Score: %.5f' % (labels[i],v))\n",
    "    # plot feature importance\n",
    "    plt.bar([x for x in range(len(importance))], importance)\n",
    "    plt.show()\n",
    "    \n",
    "# showImportance(rf_regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This notebook shows how to use machine learning models to predict the emission of coal-fired power plants using satellite observations like TROPOMI and meteorology observations from MERRA. \n",
    "\n",
    "The results show that random forest and voting ensemble models are similar in the performance. The random forest model has a slightly better performance in this case. That is also because the ensembled model is from the trained linear regression and the random forest models. The results are basically an average between the two models' results.  \n",
    "\n",
    "Linear regression model outputs basically the values in a narrow range regarless of the variances in the TROPOMI observation and never produce the values greater than 0.3 or less than 0.1. It is not suitable for this prediction. \n",
    "\n",
    "##### Final Remarks\n",
    "\n",
    "Using machine learning to predict ground emission from remote sensed data is possible. More improvements are needed to ensure the accuracy, generality, and stability of the trained models in a long-term operational run. The demonstrated power plant site is in the rural area in Alabama and there is less NO2 emission sources other than the power plant itself. More research is required to make it work for those power plants located in or nearby urban regions, where other emission sources may dominate the NOX in the atmosphere. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation\n",
    "\n",
    "Please cite this work as: \n",
    "    \n",
    "`Sun, Ziheng, Zack Chester, and Daniel Tong. 2021. \"EmissionAI: Ai Monitoring Coal-Fired Power Plant Emission from Space.\"  https://github.com/ZihengSun/EmissionAI  `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
